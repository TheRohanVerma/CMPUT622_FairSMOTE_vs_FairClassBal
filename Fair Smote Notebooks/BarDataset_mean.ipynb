{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiuqVCMgELoO"
      },
      "source": [
        "# Loading and pre-processing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS5x30JPQYYc",
        "outputId": "8437671a-9c38-43ee-f7d2-f7d2d794a8c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5k5VQa6VtvQ",
        "outputId": "65a58cc3-fd71-47ce-f974-df0ffdf787d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fairlearn\n",
            "  Downloading fairlearn-0.7.0-py3-none-any.whl (177 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 24.7 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 30 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 61 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 81 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 92 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 177 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.0.1)\n",
            "Requirement already satisfied: pandas>=0.25.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.1.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->fairlearn) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->fairlearn) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25.1->fairlearn) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->fairlearn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->fairlearn) (3.0.0)\n",
            "Installing collected packages: fairlearn\n",
            "Successfully installed fairlearn-0.7.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random,time,csv\n",
        "import numpy as np\n",
        "import math,copy,os\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn import tree\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "import sklearn.metrics as metrics\n",
        "import os\n",
        "import tempfile\n",
        "import pandas as pd\n",
        "import six.moves.urllib as urllib\n",
        "import pprint\n",
        "! pip install fairlearn\n",
        "import random\n",
        "import pandas as pd\n",
        "import random,time,csv\n",
        "import numpy as np\n",
        "import math,copy,os\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn import tree\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "import sklearn.metrics as metrics\n",
        "import os\n",
        "import tempfile\n",
        "import pandas as pd\n",
        "import six.moves.urllib as urllib\n",
        "import pprint\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "from pandas import read_csv\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from google.colab import files\n",
        "from fairlearn.reductions import BoundedGroupLoss, ZeroOneLoss\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from fairlearn.metrics import MetricFrame, selection_rate\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from google.protobuf import text_format\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.enable_v2_behavior()\n",
        "import sys\n",
        "sys.path.insert(1, '/content/drive/Shareddrives/622 - Privacy/Project Codebase/Fair-SMOTE-master/')\n",
        "from Measure import measure_final_score,calculate_recall,calculate_far,calculate_precision,calculate_accuracy\n",
        "from Generate_Samples import generate_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "WkL8oiK0Vz0O",
        "outputId": "84631a62-e603-4174-efca-8d807827c654"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dnn_bar_pass_prediction</th>\n",
              "      <th>gender</th>\n",
              "      <th>lsat</th>\n",
              "      <th>pass_bar</th>\n",
              "      <th>race1</th>\n",
              "      <th>ugpa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.979804</td>\n",
              "      <td>female</td>\n",
              "      <td>44.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>white</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.979804</td>\n",
              "      <td>female</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>white</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.979804</td>\n",
              "      <td>male</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>white</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   dnn_bar_pass_prediction  gender  lsat  pass_bar  race1  ugpa\n",
              "0                 0.979804  female  44.0       1.0  white   3.5\n",
              "1                 0.979804  female  29.0       1.0  white   3.5\n",
              "2                 0.979804    male  36.0       1.0  white   3.5"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Loading and keeping only the required columns\n",
        "\n",
        "_DATA_PATH = 'https://storage.googleapis.com/lawschool_dataset/bar_pass_prediction.csv'\n",
        "\n",
        "data = urllib.request.urlopen(_DATA_PATH)\n",
        "\n",
        "_LSAT_DF = pd.read_csv(data)\n",
        "\n",
        "\n",
        "_COLUMN_NAMES = [\n",
        "  'dnn_bar_pass_prediction',\n",
        "  'gender',\n",
        "  'lsat',\n",
        "  'pass_bar',\n",
        "  'race1',\n",
        "  'ugpa',\n",
        "]\n",
        "\n",
        "_LSAT_DF.dropna()\n",
        "_LSAT_DF['gender'] = _LSAT_DF['gender'].astype(str)\n",
        "_LSAT_DF['race1'] = _LSAT_DF['race1'].astype(str)\n",
        "df = _LSAT_DF[_COLUMN_NAMES]\n",
        "\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "_4iax3YfR4YR",
        "outputId": "36f3d721-d2d2-44eb-ebc3-09e33f30f014"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dnn_bar_pass_prediction</th>\n",
              "      <th>gender</th>\n",
              "      <th>lsat</th>\n",
              "      <th>pass_bar</th>\n",
              "      <th>ugpa</th>\n",
              "      <th>ugpa_above_threshold</th>\n",
              "      <th>asian</th>\n",
              "      <th>black</th>\n",
              "      <th>hisp</th>\n",
              "      <th>white</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.970262</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.891892</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.970262</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.486486</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.970262</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.675676</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   dnn_bar_pass_prediction  gender      lsat  ...  black  hisp  white\n",
              "0                 0.970262     0.0  0.891892  ...    0.0   0.0    1.0\n",
              "1                 0.970262     0.0  0.486486  ...    0.0   0.0    1.0\n",
              "2                 0.970262     1.0  0.675676  ...    0.0   0.0    1.0\n",
              "\n",
              "[3 rows x 10 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# creating a new binary column based on the mean of ugpa column\n",
        "# dropping null values and one hot encoding race1 columns \n",
        "# PROTECTED ATTRIBUTE IN THIS DATASET IS RACE \n",
        "\n",
        "average_gpa = df[\"ugpa\"].mean()\n",
        "\n",
        "threshold = average_gpa# taking mean of the ugpa as the threshold to create binary column\n",
        "df['ugpa_above_threshold'] = df.apply(lambda row: 1 if row['ugpa'] > threshold else 0, axis=1)\n",
        "\n",
        "df = df.dropna()\n",
        "df['gender'] = np.where(df['gender'] == 'male', 1, 0)\n",
        "\n",
        "df = df[df['race1'] != 'other']\n",
        "df = df[df['race1'] != 'nan']\n",
        "race_one_hot = pd.get_dummies(df.race1)\n",
        "_ = df.drop('race1', axis = 1)\n",
        "data = pd.concat([_,race_one_hot],axis = 1)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "data = pd.DataFrame(scaler.fit_transform(data),columns = data.columns)\n",
        "\n",
        "data.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vg8fpA57pMiY"
      },
      "outputs": [],
      "source": [
        "data_original_for_LR = data # saving for linear regression on original dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "PTQyBYO7ytUT",
        "outputId": "7f4adce1-e57b-4383-ea69-609be83b91bd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dnn_bar_pass_prediction</th>\n",
              "      <th>gender</th>\n",
              "      <th>lsat</th>\n",
              "      <th>pass_bar</th>\n",
              "      <th>ugpa</th>\n",
              "      <th>ugpa_above_threshold</th>\n",
              "      <th>asian</th>\n",
              "      <th>black</th>\n",
              "      <th>hisp</th>\n",
              "      <th>white</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>21983.000000</td>\n",
              "      <td>21983.000000</td>\n",
              "      <td>21983.000000</td>\n",
              "      <td>21983.000000</td>\n",
              "      <td>21983.000000</td>\n",
              "      <td>21983.000000</td>\n",
              "      <td>21983.000000</td>\n",
              "      <td>21983.000000</td>\n",
              "      <td>21983.000000</td>\n",
              "      <td>21983.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.971683</td>\n",
              "      <td>0.560751</td>\n",
              "      <td>0.697155</td>\n",
              "      <td>0.948824</td>\n",
              "      <td>0.715371</td>\n",
              "      <td>0.499522</td>\n",
              "      <td>0.040804</td>\n",
              "      <td>0.061093</td>\n",
              "      <td>0.046718</td>\n",
              "      <td>0.851385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.033513</td>\n",
              "      <td>0.496307</td>\n",
              "      <td>0.147135</td>\n",
              "      <td>0.220361</td>\n",
              "      <td>0.168155</td>\n",
              "      <td>0.500011</td>\n",
              "      <td>0.197841</td>\n",
              "      <td>0.239506</td>\n",
              "      <td>0.211039</td>\n",
              "      <td>0.355716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.957207</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.594595</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.975254</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.702703</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.708333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.995258</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.810811</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       dnn_bar_pass_prediction        gender  ...          hisp         white\n",
              "count             21983.000000  21983.000000  ...  21983.000000  21983.000000\n",
              "mean                  0.971683      0.560751  ...      0.046718      0.851385\n",
              "std                   0.033513      0.496307  ...      0.211039      0.355716\n",
              "min                   0.000000      0.000000  ...      0.000000      0.000000\n",
              "25%                   0.957207      0.000000  ...      0.000000      1.000000\n",
              "50%                   0.975254      1.000000  ...      0.000000      1.000000\n",
              "75%                   0.995258      1.000000  ...      0.000000      1.000000\n",
              "max                   1.000000      1.000000  ...      1.000000      1.000000\n",
              "\n",
              "[8 rows x 10 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21kcB0JBDO5T",
        "outputId": "76ed7c22-96f7-4356-8290-1fae49808df8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7153709684755347\n"
          ]
        }
      ],
      "source": [
        "threshold =data[\"ugpa\"].mean() # saving normalised mean for Statistical Parity\n",
        "print(threshold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBojU0xSFYkv"
      },
      "source": [
        "# Oversampling and removing biased labels using Fair-SMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_Hy-85nU6Lq"
      },
      "source": [
        "## Oversampling "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KQD3LK_ZkG4",
        "outputId": "96ec815b-94e0-46e9-eb3b-202cfc035eef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instance count of different columns is -- 298 1045 9861 8855 362 665 460 437\n"
          ]
        }
      ],
      "source": [
        "# Creating subgroups according to race and values of ugpa_above_average column\n",
        "# checking instance count of different subgroups\n",
        "black_ab_av = len(data[(data['ugpa_above_threshold'] == 1) & (data['black'] == 1)])\n",
        "black_bl_av= len(data[(data['ugpa_above_threshold'] == 0) & (data['black'] == 1)])\n",
        "white_ab_av= len(data[(data['ugpa_above_threshold'] == 1) & (data['white'] == 1)])\n",
        "white_bl_av= len(data[(data['ugpa_above_threshold'] == 0) & (data['white'] == 1)])\n",
        "hisp_ab_av= len(data[(data['ugpa_above_threshold'] == 1) & (data['hisp'] == 1)])\n",
        "hisp_bl_av= len(data[(data['ugpa_above_threshold'] == 0) & (data['hisp'] == 1)])\n",
        "asian_ab_av= len(data[(data['ugpa_above_threshold'] == 1) & (data['asian'] == 1)])\n",
        "asian_bl_av= len(data[(data['ugpa_above_threshold'] == 0) & (data['asian'] == 1)])\n",
        "\n",
        "print('Instance count of different columns is --',black_ab_av,black_bl_av,white_ab_av,white_bl_av,hisp_ab_av,hisp_bl_av,asian_ab_av,asian_bl_av)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJr-dWKlXKA_"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nml93wjXZm2z"
      },
      "outputs": [],
      "source": [
        "maximum = max(black_ab_av,black_bl_av,white_ab_av,white_bl_av,hisp_ab_av,hisp_bl_av,asian_ab_av,asian_bl_av)\n",
        "# white students with ugpa > average are more \n",
        "# therefore, increasing size of other subgroups\n",
        "black_ab_av_to_be_incresed = maximum - black_ab_av\n",
        "black_bl_av_to_be_incresed = maximum - black_bl_av \n",
        "white_bl_av_to_be_incresed = maximum - white_bl_av \n",
        "hisp_ab_av_to_be_incresed = maximum - hisp_ab_av\n",
        "hisp_bl_av_to_be_incresed = maximum - hisp_bl_av \n",
        "asian_ab_av_to_be_incresed = maximum - asian_ab_av \n",
        "asian_bl_av_to_be_incresed = maximum - asian_bl_av \n",
        "\n",
        "df_black_ab_av = (data[(data['ugpa_above_threshold'] == 1) & (data['black'] == 1)])\n",
        "df_black_bl_av= (data[(data['ugpa_above_threshold'] == 0) & (data['black'] == 1)])\n",
        "df_white_bl_av= (data[(data['ugpa_above_threshold'] == 0) & (data['white'] == 1)])\n",
        "df_hisp_ab_av= (data[(data['ugpa_above_threshold'] == 1) & (data['hisp'] == 1)])\n",
        "df_hisp_bl_av= (data[(data['ugpa_above_threshold'] == 0) & (data['hisp'] == 1)])\n",
        "df_asian_ab_av= (data[(data['ugpa_above_threshold'] == 1) & (data['asian'] == 1)])\n",
        "df_asian_bl_av= (data[(data['ugpa_above_threshold'] == 0) & (data['asian'] == 1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mqwzm_dvt-O-"
      },
      "outputs": [],
      "source": [
        "# generating samples and making instance counts equal to the count of largest subgroup \n",
        "# using Generate samples function given by FairSMOTE authors. It uses KNN\n",
        "df_black_ab_av = generate_samples(black_ab_av_to_be_incresed,df_black_ab_av,'law').rename(columns={0:\"dnn_bar_pass_prediction\",1:\"gender\",2:\"lsat\",3:\"pass_bar\",4:'ugpa',5:\"ugpa_above_threshold\",6:\"asian\",7:\"black\",8:\"hisp\",9:\"white\"})\n",
        "df_black_bl_av= generate_samples(black_bl_av_to_be_incresed,df_black_bl_av,'law').rename(columns={0:\"dnn_bar_pass_prediction\",1:\"gender\",2:\"lsat\",3:\"pass_bar\",4:'ugpa',5:\"ugpa_above_threshold\",6:\"asian\",7:\"black\",8:\"hisp\",9:\"white\"})\n",
        "df_white_bl_av= generate_samples(white_bl_av_to_be_incresed,df_white_bl_av,'law').rename(columns={0:\"dnn_bar_pass_prediction\",1:\"gender\",2:\"lsat\",3:\"pass_bar\",4:'ugpa',5:\"ugpa_above_threshold\",6:\"asian\",7:\"black\",8:\"hisp\",9:\"white\"})\n",
        "df_hisp_ab_av= generate_samples(hisp_ab_av_to_be_incresed,df_hisp_ab_av,'law').rename(columns={0:\"dnn_bar_pass_prediction\",1:\"gender\",2:\"lsat\",3:\"pass_bar\",4:'ugpa',5:\"ugpa_above_threshold\",6:\"asian\",7:\"black\",8:\"hisp\",9:\"white\"})\n",
        "df_hisp_bl_av= generate_samples(hisp_bl_av_to_be_incresed,df_hisp_bl_av,'law').rename(columns={0:\"dnn_bar_pass_prediction\",1:\"gender\",2:\"lsat\",3:\"pass_bar\",4:'ugpa',5:\"ugpa_above_threshold\",6:\"asian\",7:\"black\",8:\"hisp\",9:\"white\"})\n",
        "df_asian_ab_av= generate_samples(asian_ab_av_to_be_incresed,df_asian_ab_av,'law').rename(columns={0:\"dnn_bar_pass_prediction\",1:\"gender\",2:\"lsat\",3:\"pass_bar\",4:'ugpa',5:\"ugpa_above_threshold\",6:\"asian\",7:\"black\",8:\"hisp\",9:\"white\"})\n",
        "df_asian_bl_av= generate_samples(asian_bl_av_to_be_incresed,df_asian_bl_av,'law').rename(columns={0:\"dnn_bar_pass_prediction\",1:\"gender\",2:\"lsat\",3:\"pass_bar\",4:'ugpa',5:\"ugpa_above_threshold\",6:\"asian\",7:\"black\",8:\"hisp\",9:\"white\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukAJuUVOls5M",
        "outputId": "18fe31d1-97c7-4af8-df1f-f030a25e2535"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The oversampled data has shape -- (78888, 10)\n"
          ]
        }
      ],
      "source": [
        "df_white_ab_av= (data[(data['ugpa_above_threshold'] == 1) & (data['white'] == 1)])\n",
        "# combining all the oversampled aubgroups\n",
        "data_oversampled_main = df_white_ab_av.append([df_black_ab_av,df_black_bl_av,df_white_bl_av,df_hisp_ab_av,df_hisp_bl_av,df_asian_ab_av,df_asian_bl_av])\n",
        "data_oversampled = data_oversampled_main\n",
        "print('The oversampled data has shape --',data_oversampled.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9YP3AJRsMDx"
      },
      "source": [
        "## Removal of biased data points using situation testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KoJkD51jyv8",
        "outputId": "ae13daa0-c6bd-4473-8c6a-413263ce6684"
      },
      "outputs": [],
      "source": [
        "data_oversampled['new_index'] = range(0,78888) # fair SMOTE implementation return repetitive indexes according to the subgroup\n",
        "_data_oversampled = data_oversampled.set_index('new_index')\n",
        "\n",
        "X_train, y_train = _data_oversampled.loc[:, _data_oversampled.columns != 'ugpa_above_threshold'], _data_oversampled['ugpa_above_threshold']\n",
        "\n",
        "clf = LogisticRegression(C=1.0, penalty='l2', solver='liblinear', max_iter=100)\n",
        "clf.fit(X_train,y_train)\n",
        "removal_list = []\n",
        "\n",
        "for index,row in X_train.iterrows():\n",
        "    row_ = [row.values[0:len(row.values)]]    \n",
        "    y_normal = clf.predict(row_)\n",
        "\n",
        "    #switching for asian\n",
        "\n",
        "    if row_[0][5] == 1:\n",
        "      change_to_1 = random.choice([6,7,8])\n",
        "      row_[0][5] = 0\n",
        "      row_[0][change_to_1] = 1   \n",
        "      y_reverse = clf.predict(row_)\n",
        "      if y_normal[0] != y_reverse[0]:\n",
        "          removal_list.append(index)\n",
        "\n",
        "    #switching for black\n",
        "\n",
        "    if row_[0][6] == 1:\n",
        "      change_to_1 = random.choice([5,7,8])\n",
        "      row_[0][6] = 0\n",
        "      row_[0][change_to_1] = 1   \n",
        "      y_reverse = clf.predict(row_)\n",
        "      if y_normal[0] != y_reverse[0]:\n",
        "          removal_list.append(index)\n",
        "\n",
        "    #switching for hisp\n",
        "\n",
        "    if row_[0][7] == 1:\n",
        "      change_to_1 = random.choice([5,6,8])\n",
        "      row_[0][7] = 0\n",
        "      row_[0][change_to_1] = 1   \n",
        "      y_reverse = clf.predict(row_)\n",
        "      if y_normal[0] != y_reverse[0]:\n",
        "          removal_list.append(index)\n",
        "\n",
        "    #switching for white\n",
        "\n",
        "    if row_[0][8] == 1:\n",
        "      change_to_1 = random.choice([5,6,7])\n",
        "      row_[0][8] = 0\n",
        "      row_[0][change_to_1] = 1   \n",
        "      y_reverse = clf.predict(row_)\n",
        "      if y_normal[0] != y_reverse[0]:\n",
        "          removal_list.append(index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVSiU_dn6bai",
        "outputId": "c74c06bd-7e4e-4d07-d003-54cb50965616"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A total of 346 instances are biased and will be removed\n"
          ]
        }
      ],
      "source": [
        "removal_list = list(set(removal_list))\n",
        "print(f'A total of {len(removal_list)} instances are biased and will be removed')\n",
        "\n",
        "_df = data_oversampled\n",
        "_remov = removal_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbKQvvuo81th",
        "outputId": "382ec7d0-3079-4fa6-b95a-17309442883c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of final dataset is  78542\n"
          ]
        }
      ],
      "source": [
        "# removing biased datapoints \n",
        "final = _data_oversampled.drop(_data_oversampled.index[list(set(removal_list))])\n",
        "print('Size of final dataset is ',len(final))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZfQWXW1-l9m"
      },
      "outputs": [],
      "source": [
        "# uncomment to save dataset\n",
        "\n",
        "# final.to_csv('fairSMOTE.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGgwqrDSHshv"
      },
      "source": [
        "# Evaluation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccz88jSer8Y7"
      },
      "source": [
        "## Linear Regression on balanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIQoAW_xZzg4",
        "outputId": "2e798fec-8801-4e9b-919f-03a7413b4990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear regression with protected attribute\n",
            "Intercept:  -3196644796858.451\n",
            "Root Mean Square Error:  0.13468272764688713\n",
            "R^2 Value:  0.424012898509898\n"
          ]
        }
      ],
      "source": [
        "# training linear regression model to evaluate \n",
        "data_oversampled_onlyugpa = final.drop('ugpa_above_threshold',axis = 1)\n",
        "df = data_oversampled_onlyugpa\n",
        "X = df.iloc[:,df.columns != 'ugpa']\n",
        "\n",
        "Y = df['ugpa']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state= 0)\n",
        "\n",
        "model = linear_model.LinearRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "y_pred_w_prot_attr = model.predict(X_test)\n",
        "\n",
        "rmsd = np.sqrt(mean_squared_error(Y_test, y_pred_w_prot_attr))      \n",
        "r2_value = r2_score(Y_test, y_pred_w_prot_attr)                     \n",
        "                   \n",
        "print('Linear regression with protected attribute')\n",
        "\n",
        "print(\"Intercept: \", model.intercept_)\n",
        "print(\"Root Mean Square Error: \", rmsd)\n",
        "print(\"R^2 Value: \", r2_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_g8w2AG3JSV",
        "outputId": "84300a31-06be-46cd-f12c-05d0da94d154"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear regression without protected attribute\n",
            "Intercept:  -1.9728018139650847\n",
            "Root Mean Square Error:  0.13467375397100026\n",
            "R^2 Value:  0.4240896499903978\n"
          ]
        }
      ],
      "source": [
        "# Linear regression without protected attribute \n",
        "_df = final.drop(['asian','black','hisp','white','ugpa_above_threshold'], axis = 1)\n",
        "X = _df.iloc[:,_df.columns != 'ugpa']\n",
        "Y = _df['ugpa']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state= 0)\n",
        "\n",
        "model = linear_model.LinearRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "y_pred_wo_prot_attr = model.predict(X_test)\n",
        "\n",
        "rmsd = np.sqrt(mean_squared_error(Y_test, y_pred_wo_prot_attr))      \n",
        "r2_value = r2_score(Y_test, y_pred_wo_prot_attr)  \n",
        "                   \n",
        "print('Linear regression without protected attribute')\n",
        "print(\"Intercept: \", model.intercept_)\n",
        "print(\"Root Mean Square Error: \", rmsd)\n",
        "print(\"R^2 Value: \", r2_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1EYiE883kyY",
        "outputId": "5c45c40a-d09c-41ef-9a4d-68a8e963661c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Statistical Parity is  0.002991915462473793\n"
          ]
        }
      ],
      "source": [
        "# Statistical Parity\n",
        "\n",
        "averageCounter = 0\n",
        "\n",
        "for entry in y_pred_w_prot_attr:\n",
        "  if entry > threshold : averageCounter+=1\n",
        "\n",
        "prob_w_prot_attr = averageCounter/len(y_pred_w_prot_attr)\n",
        "\n",
        "\n",
        "averageCounter = 0\n",
        "for entry in y_pred_wo_prot_attr:\n",
        "  if entry > threshold : averageCounter+=1\n",
        "\n",
        "prob_wo_prot_attr = averageCounter/len(y_pred_wo_prot_attr)\n",
        "\n",
        "print('Statistical Parity is ', abs(prob_w_prot_attr-prob_wo_prot_attr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Hux2nxfrNvP",
        "outputId": "9333c5f8-b4d2-41dc-d101-736b8041978f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.10925311773903493\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fairlearn/metrics/_metric_frame.py:67: FutureWarning: You have provided 'metrics', 'y_true', 'y_pred' as positional arguments. Please pass them as keyword arguments. From version 0.10.0 passing them as positional arguments will result in an error.\n",
            "  FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# Bounded Group Loss\n",
        "\n",
        "def apply_complex_function(x): \n",
        "  if x['black'] == 1:\n",
        "    return 0\n",
        "  if x['asian'] == 1:\n",
        "    return 2\n",
        "  if x['white'] == 1:\n",
        "    return 1\n",
        "  if x['hisp'] == 1:\n",
        "    return 3\n",
        "\n",
        "\n",
        "df['race'] = df.apply(apply_complex_function, axis=1) \n",
        "  \n",
        "  \n",
        "df = df.drop(['asian','black','hisp','white'], axis = 1)\n",
        "X = df.iloc[:,df.columns != 'ugpa']\n",
        "Y = df['ugpa']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state= 0)\n",
        "\n",
        "\n",
        "bgl = BoundedGroupLoss(ZeroOneLoss(), upper_bound=0.1)\n",
        "sensitive_features = np.array(list(X_test['race'].values))\n",
        "mae_frame = MetricFrame(mean_absolute_error,\n",
        "                        Y_test, y_pred_w_prot_attr,\n",
        "                        sensitive_features=pd.Series(sensitive_features, name=\"SF 0\"))\n",
        "print(mae_frame.overall)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6whSkM6JubPy"
      },
      "source": [
        "## Linear Regression on original dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRU9F9i0pZfd",
        "outputId": "eebdd365-b326-479f-aa80-cf5f57aee6a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear regression with protected attribute on original dataset\n",
            "Intercept:  -2.397809909107653\n",
            "Root Mean Square Error:  0.12922763080234756\n",
            "R^2 Value:  0.4148279848480254\n"
          ]
        }
      ],
      "source": [
        "# training linear regression model on the original dataset\n",
        "\n",
        "data_original = data_original_for_LR.drop('ugpa_above_threshold',axis = 1)\n",
        "X = data_original.iloc[:,data_original.columns != 'ugpa']\n",
        "Y = data_original['ugpa']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state= 0)\n",
        "\n",
        "model = linear_model.LinearRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "y_pred_w_prot_attr = model.predict(X_test)\n",
        "\n",
        "rmsd = np.sqrt(mean_squared_error(Y_test, y_pred_w_prot_attr))      \n",
        "r2_value = r2_score(Y_test, y_pred_w_prot_attr)                     \n",
        "\n",
        "print('Linear regression with protected attribute on original dataset')\n",
        "print(\"Intercept: \", model.intercept_)\n",
        "print(\"Root Mean Square Error: \", rmsd)\n",
        "print(\"R^2 Value: \", r2_value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OV-5ykJ81rUN",
        "outputId": "4ce7f6aa-275d-4ade-c7dc-9638ae57f463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear regression without protected attribute on original dataset\n",
            "Intercept:  -2.449361233318119\n",
            "Root Mean Square Error:  0.12985725205722876\n",
            "R^2 Value:  0.4091119582884615\n"
          ]
        }
      ],
      "source": [
        "# training linear regression model without protected attributes\n",
        "\n",
        "data_original_norace = data_original_for_LR.drop(['asian','black','hisp','white','ugpa_above_threshold'],axis = 1)\n",
        "X = data_original_norace.iloc[:,data_original_norace.columns != 'ugpa']\n",
        "Y = data_original_norace['ugpa']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state= 0)\n",
        "\n",
        "model = linear_model.LinearRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "y_pred_wo_prot_attr = model.predict(X_test)\n",
        "\n",
        "rmsd = np.sqrt(mean_squared_error(Y_test, y_pred_wo_prot_attr))      \n",
        "r2_value = r2_score(Y_test, y_pred_wo_prot_attr)                     \n",
        "print('Linear regression without protected attribute on original dataset')\n",
        "print(\"Intercept: \", model.intercept_)\n",
        "print(\"Root Mean Square Error: \", rmsd)\n",
        "print(\"R^2 Value: \", r2_value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieKL5lxRI8pm",
        "outputId": "f0e760f1-2b9c-4a66-936e-f6eb72737433"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Statistical Parity is  0.00614055037525596\n"
          ]
        }
      ],
      "source": [
        "# Statistical Parity\n",
        "\n",
        "averageCounter = 0\n",
        "for entry in y_pred_w_prot_attr:\n",
        "  if entry > threshold : averageCounter+=1\n",
        "prob_w_prot_attr = averageCounter/len(y_pred_w_prot_attr)\n",
        "\n",
        "averageCounter = 0\n",
        "for entry in y_pred_wo_prot_attr:\n",
        "  if entry > threshold : averageCounter+=1\n",
        "prob_wo_prot_attr = averageCounter/len(y_pred_wo_prot_attr)\n",
        "\n",
        "print('Statistical Parity is ', abs(prob_w_prot_attr-prob_wo_prot_attr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2fcfHHeqlQv",
        "outputId": "31d50de0-90cf-48ae-f137-3d814ac5bcbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.10278870312112617\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fairlearn/metrics/_metric_frame.py:67: FutureWarning: You have provided 'metrics', 'y_true', 'y_pred' as positional arguments. Please pass them as keyword arguments. From version 0.10.0 passing them as positional arguments will result in an error.\n",
            "  FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# Bounded group loss \n",
        "\n",
        "def apply_complex_function(x): \n",
        "  if x['black'] == 1:\n",
        "    return 0\n",
        "  if x['asian'] == 1:\n",
        "    return 2\n",
        "  if x['white'] == 1:\n",
        "    return 1\n",
        "  if x['hisp'] == 1:\n",
        "    return 3\n",
        "\n",
        "data_original=data_original_for_LR\n",
        "data_original['race'] = data_original.apply(apply_complex_function, axis=1) \n",
        "\n",
        "\n",
        "data_original = data_original.drop(['asian','black','hisp','white'], axis = 1)\n",
        "X = data_original.iloc[:,data_original.columns != 'ugpa']\n",
        "Y = data_original['ugpa']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state= 0)\n",
        "\n",
        "\n",
        "bgl = BoundedGroupLoss(ZeroOneLoss(), upper_bound=0.1)\n",
        "sensitive_features = np.array(list(X_test['race'].values))\n",
        "mae_frame = MetricFrame(mean_absolute_error,\n",
        "                        Y_test, y_pred_w_prot_attr,\n",
        "                        sensitive_features=pd.Series(sensitive_features, name=\"SF 0\"))\n",
        "print(mae_frame.overall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFH59C2c0nwb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "BarDataset_mean.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
