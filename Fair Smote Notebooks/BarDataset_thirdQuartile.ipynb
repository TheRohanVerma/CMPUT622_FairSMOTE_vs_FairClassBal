{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiuqVCMgELoO"
      },
      "source": [
        "# Loading and pre-processing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS5x30JPQYYc",
        "outputId": "24d0695c-a83b-47a7-a02a-f083a5487c66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5k5VQa6VtvQ",
        "outputId": "cb5f1f8b-b00a-43c7-ae46-a2764a3b8fd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fairlearn in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.25.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->fairlearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->fairlearn) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25.1->fairlearn) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->fairlearn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->fairlearn) (3.0.0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random,time,csv\n",
        "import numpy as np\n",
        "import math,copy,os\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn import tree\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "import sklearn.metrics as metrics\n",
        "import os\n",
        "import tempfile\n",
        "import pandas as pd\n",
        "import six.moves.urllib as urllib\n",
        "import pprint\n",
        "! pip install fairlearn\n",
        "import random\n",
        "import pandas as pd\n",
        "import random,time,csv\n",
        "import numpy as np\n",
        "import math,copy,os\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn import tree\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "import sklearn.metrics as metrics\n",
        "import os\n",
        "import tempfile\n",
        "import pandas as pd\n",
        "import six.moves.urllib as urllib\n",
        "import pprint\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "from pandas import read_csv\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from google.colab import files\n",
        "from fairlearn.reductions import BoundedGroupLoss, ZeroOneLoss\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from fairlearn.metrics import MetricFrame, selection_rate\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from google.protobuf import text_format\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.enable_v2_behavior()\n",
        "import sys\n",
        "sys.path.insert(1, '/content/drive/Shareddrives/622 - Privacy/Project Codebase/Fair-SMOTE-master')\n",
        "from Measure import measure_final_score,calculate_recall,calculate_far,calculate_precision,calculate_accuracy\n",
        "from Generate_Samples import generate_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "WkL8oiK0Vz0O",
        "outputId": "e14f954a-c49f-488f-976a-1dbeb39a1980"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dnn_bar_pass_prediction</th>\n",
              "      <th>gender</th>\n",
              "      <th>lsat</th>\n",
              "      <th>pass_bar</th>\n",
              "      <th>race1</th>\n",
              "      <th>ugpa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.979804</td>\n",
              "      <td>female</td>\n",
              "      <td>44.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>white</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.979804</td>\n",
              "      <td>female</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>white</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.979804</td>\n",
              "      <td>male</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>white</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   dnn_bar_pass_prediction  gender  lsat  pass_bar  race1  ugpa\n",
              "0                 0.979804  female  44.0       1.0  white   3.5\n",
              "1                 0.979804  female  29.0       1.0  white   3.5\n",
              "2                 0.979804    male  36.0       1.0  white   3.5"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Loading and keeping only the required columns\n",
        "\n",
        "_DATA_PATH = 'https://storage.googleapis.com/lawschool_dataset/bar_pass_prediction.csv'\n",
        "\n",
        "data = urllib.request.urlopen(_DATA_PATH)\n",
        "\n",
        "_LSAT_DF = pd.read_csv(data)\n",
        "\n",
        "\n",
        "_COLUMN_NAMES = [\n",
        "  'dnn_bar_pass_prediction',\n",
        "  'gender',\n",
        "  'lsat',\n",
        "  'pass_bar',\n",
        "  'race1',\n",
        "  'ugpa',\n",
        "]\n",
        "\n",
        "_LSAT_DF.dropna()\n",
        "_LSAT_DF['gender'] = _LSAT_DF['gender'].astype(str)\n",
        "_LSAT_DF['race1'] = _LSAT_DF['race1'].astype(str)\n",
        "df = _LSAT_DF[_COLUMN_NAMES]\n",
        "\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "uFONqzmDx_An",
        "outputId": "a7abad17-b89f-45db-eaf0-db7311b86b65"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dnn_bar_pass_prediction</th>\n",
              "      <th>lsat</th>\n",
              "      <th>pass_bar</th>\n",
              "      <th>ugpa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>22407.000000</td>\n",
              "      <td>22407.000000</td>\n",
              "      <td>22407.000000</td>\n",
              "      <td>22407.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.980682</td>\n",
              "      <td>36.767907</td>\n",
              "      <td>0.947829</td>\n",
              "      <td>3.215451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.022594</td>\n",
              "      <td>5.463248</td>\n",
              "      <td>0.222377</td>\n",
              "      <td>0.404073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.330740</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.971071</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.983144</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.996526</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.999698</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.900000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       dnn_bar_pass_prediction          lsat      pass_bar          ugpa\n",
              "count             22407.000000  22407.000000  22407.000000  22407.000000\n",
              "mean                  0.980682     36.767907      0.947829      3.215451\n",
              "std                   0.022594      5.463248      0.222377      0.404073\n",
              "min                   0.330740     11.000000      0.000000      1.500000\n",
              "25%                   0.971071     33.000000      1.000000      3.000000\n",
              "50%                   0.983144     37.000000      1.000000      3.200000\n",
              "75%                   0.996526     41.000000      1.000000      3.500000\n",
              "max                   0.999698     48.000000      1.000000      3.900000"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()\n",
        "# taking 75% i.e. 3.5 as the threshold "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "_4iax3YfR4YR",
        "outputId": "93cd6fc2-a284-42dc-fa4e-71c0e9b9d663"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dnn_bar_pass_prediction</th>\n",
              "      <th>gender</th>\n",
              "      <th>lsat</th>\n",
              "      <th>pass_bar</th>\n",
              "      <th>ugpa</th>\n",
              "      <th>ugpa_above_threshold</th>\n",
              "      <th>asian</th>\n",
              "      <th>black</th>\n",
              "      <th>hisp</th>\n",
              "      <th>white</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.970262</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.891892</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.970262</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.486486</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.970262</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.675676</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   dnn_bar_pass_prediction  gender      lsat  ...  black  hisp  white\n",
              "0                 0.970262     0.0  0.891892  ...    0.0   0.0    1.0\n",
              "1                 0.970262     0.0  0.486486  ...    0.0   0.0    1.0\n",
              "2                 0.970262     1.0  0.675676  ...    0.0   0.0    1.0\n",
              "\n",
              "[3 rows x 10 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# creating a new binary column based on the third quartile of ugpa column\n",
        "# dropping null values and one hot encoding race1 columns \n",
        "# PROTECTED ATTRIBUTE IN THIS DATASET IS RACE \n",
        "third_quartile = 3.5\n",
        "\n",
        "threshold = third_quartile# taking first quartile of the ugpa as the threshold to create binary column\n",
        "df['ugpa_above_threshold'] = df.apply(lambda row: 1 if row['ugpa'] > threshold else 0, axis=1)\n",
        "\n",
        "df = df.dropna()\n",
        "df['gender'] = np.where(df['gender'] == 'male', 1, 0)\n",
        "\n",
        "df = df[df['race1'] != 'other']\n",
        "df = df[df['race1'] != 'nan']\n",
        "race_one_hot = pd.get_dummies(df.race1)\n",
        "_ = df.drop('race1', axis = 1)\n",
        "data = pd.concat([_,race_one_hot],axis = 1)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "data = pd.DataFrame(scaler.fit_transform(data),columns = data.columns)\n",
        "\n",
        "data.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vg8fpA57pMiY"
      },
      "outputs": [],
      "source": [
        "data_original = data # saving for linear regression on original dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "PTQyBYO7ytUT",
        "outputId": "9b73c1c5-de2c-4577-b96a-8837637d1238"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dnn_bar_pass_prediction</th>\n",
              "      <th>gender</th>\n",
              "      <th>lsat</th>\n",
              "      <th>pass_bar</th>\n",
              "      <th>ugpa</th>\n",
              "      <th>ugpa_above_threshold</th>\n",
              "      <th>asian</th>\n",
              "      <th>black</th>\n",
              "      <th>hisp</th>\n",
              "      <th>white</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>21983.000000</td>\n",
              "      <td>21983.000000</td>\n",
              "      <td>21983.000000</td>\n",
              "      <td>21983.000000</td>\n",
              "      <td>21983.000000</td>\n",
              "      <td>21983.000000</td>\n",
              "      <td>21983.000000</td>\n",
              "      <td>21983.000000</td>\n",
              "      <td>21983.000000</td>\n",
              "      <td>21983.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.971683</td>\n",
              "      <td>0.560751</td>\n",
              "      <td>0.697155</td>\n",
              "      <td>0.948824</td>\n",
              "      <td>0.715371</td>\n",
              "      <td>0.230314</td>\n",
              "      <td>0.040804</td>\n",
              "      <td>0.061093</td>\n",
              "      <td>0.046718</td>\n",
              "      <td>0.851385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.033513</td>\n",
              "      <td>0.496307</td>\n",
              "      <td>0.147135</td>\n",
              "      <td>0.220361</td>\n",
              "      <td>0.168155</td>\n",
              "      <td>0.421044</td>\n",
              "      <td>0.197841</td>\n",
              "      <td>0.239506</td>\n",
              "      <td>0.211039</td>\n",
              "      <td>0.355716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.957207</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.594595</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.975254</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.702703</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.708333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.995258</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.810811</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       dnn_bar_pass_prediction        gender  ...          hisp         white\n",
              "count             21983.000000  21983.000000  ...  21983.000000  21983.000000\n",
              "mean                  0.971683      0.560751  ...      0.046718      0.851385\n",
              "std                   0.033513      0.496307  ...      0.211039      0.355716\n",
              "min                   0.000000      0.000000  ...      0.000000      0.000000\n",
              "25%                   0.957207      0.000000  ...      0.000000      1.000000\n",
              "50%                   0.975254      1.000000  ...      0.000000      1.000000\n",
              "75%                   0.995258      1.000000  ...      0.000000      1.000000\n",
              "max                   1.000000      1.000000  ...      1.000000      1.000000\n",
              "\n",
              "[8 rows x 10 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21kcB0JBDO5T"
      },
      "outputs": [],
      "source": [
        "threshold =0.833 # saving normalised second quartile for Statistical Parity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBojU0xSFYkv"
      },
      "source": [
        "# Oversampling and removing biased labels using Fair-SMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_Hy-85nU6Lq"
      },
      "source": [
        "## Oversampling "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KQD3LK_ZkG4",
        "outputId": "527404f6-fc40-44ea-cc65-802d622b01bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instance count of different columns is -- 100 1243 4598 14118 145 882 220 677\n"
          ]
        }
      ],
      "source": [
        "# Creating subgroups according to race and values of ugpa_above_average column\n",
        "# checking instance count of different subgroups\n",
        "black_ab_av = len(data[(data['ugpa_above_threshold'] == 1) & (data['black'] == 1)])\n",
        "black_bl_av= len(data[(data['ugpa_above_threshold'] == 0) & (data['black'] == 1)])\n",
        "white_ab_av= len(data[(data['ugpa_above_threshold'] == 1) & (data['white'] == 1)])\n",
        "white_bl_av= len(data[(data['ugpa_above_threshold'] == 0) & (data['white'] == 1)])\n",
        "hisp_ab_av= len(data[(data['ugpa_above_threshold'] == 1) & (data['hisp'] == 1)])\n",
        "hisp_bl_av= len(data[(data['ugpa_above_threshold'] == 0) & (data['hisp'] == 1)])\n",
        "asian_ab_av= len(data[(data['ugpa_above_threshold'] == 1) & (data['asian'] == 1)])\n",
        "asian_bl_av= len(data[(data['ugpa_above_threshold'] == 0) & (data['asian'] == 1)])\n",
        "\n",
        "print('Instance count of different columns is --',black_ab_av,black_bl_av,white_ab_av,white_bl_av,hisp_ab_av,hisp_bl_av,asian_ab_av,asian_bl_av)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJr-dWKlXKA_"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nml93wjXZm2z"
      },
      "outputs": [],
      "source": [
        "maximum = max(black_ab_av,black_bl_av,white_ab_av,white_bl_av,hisp_ab_av,hisp_bl_av,asian_ab_av,asian_bl_av)\n",
        "# white students with ugpa < average are more \n",
        "# therefore, increasing size of other subgroups\n",
        "\n",
        "black_ab_av_to_be_incresed = maximum - black_ab_av\n",
        "black_bl_av_to_be_incresed = maximum - black_bl_av \n",
        "white_ab_av_to_be_incresed = maximum - white_ab_av \n",
        "hisp_ab_av_to_be_incresed = maximum - hisp_ab_av\n",
        "hisp_bl_av_to_be_incresed = maximum - hisp_bl_av \n",
        "asian_ab_av_to_be_incresed = maximum - asian_ab_av \n",
        "asian_bl_av_to_be_incresed = maximum - asian_bl_av \n",
        "\n",
        "df_black_ab_av = (data[(data['ugpa_above_threshold'] == 1) & (data['black'] == 1)])\n",
        "df_black_bl_av= (data[(data['ugpa_above_threshold'] == 0) & (data['black'] == 1)])\n",
        "df_white_ab_av= (data[(data['ugpa_above_threshold'] == 1) & (data['white'] == 1)])\n",
        "df_hisp_ab_av= (data[(data['ugpa_above_threshold'] == 1) & (data['hisp'] == 1)])\n",
        "df_hisp_bl_av= (data[(data['ugpa_above_threshold'] == 0) & (data['hisp'] == 1)])\n",
        "df_asian_ab_av= (data[(data['ugpa_above_threshold'] == 1) & (data['asian'] == 1)])\n",
        "df_asian_bl_av= (data[(data['ugpa_above_threshold'] == 0) & (data['asian'] == 1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mqwzm_dvt-O-"
      },
      "outputs": [],
      "source": [
        "# generating samples and making instance counts equal to the count of largest subgroup \n",
        "# using Generate samples function given by FairSMOTE authors. It uses KNN\n",
        "df_black_ab_av = generate_samples(black_ab_av_to_be_incresed,df_black_ab_av,'law').rename(columns={0:\"dnn_bar_pass_prediction\",1:\"gender\",2:\"lsat\",3:\"pass_bar\",4:'ugpa',5:\"ugpa_above_threshold\",6:\"asian\",7:\"black\",8:\"hisp\",9:\"white\"})\n",
        "df_black_bl_av= generate_samples(black_bl_av_to_be_incresed,df_black_bl_av,'law').rename(columns={0:\"dnn_bar_pass_prediction\",1:\"gender\",2:\"lsat\",3:\"pass_bar\",4:'ugpa',5:\"ugpa_above_threshold\",6:\"asian\",7:\"black\",8:\"hisp\",9:\"white\"})\n",
        "df_white_ab_av= generate_samples(white_ab_av_to_be_incresed,df_white_ab_av,'law').rename(columns={0:\"dnn_bar_pass_prediction\",1:\"gender\",2:\"lsat\",3:\"pass_bar\",4:'ugpa',5:\"ugpa_above_threshold\",6:\"asian\",7:\"black\",8:\"hisp\",9:\"white\"})\n",
        "df_hisp_ab_av= generate_samples(hisp_ab_av_to_be_incresed,df_hisp_ab_av,'law').rename(columns={0:\"dnn_bar_pass_prediction\",1:\"gender\",2:\"lsat\",3:\"pass_bar\",4:'ugpa',5:\"ugpa_above_threshold\",6:\"asian\",7:\"black\",8:\"hisp\",9:\"white\"})\n",
        "df_hisp_bl_av= generate_samples(hisp_bl_av_to_be_incresed,df_hisp_bl_av,'law').rename(columns={0:\"dnn_bar_pass_prediction\",1:\"gender\",2:\"lsat\",3:\"pass_bar\",4:'ugpa',5:\"ugpa_above_threshold\",6:\"asian\",7:\"black\",8:\"hisp\",9:\"white\"})\n",
        "df_asian_ab_av= generate_samples(asian_ab_av_to_be_incresed,df_asian_ab_av,'law').rename(columns={0:\"dnn_bar_pass_prediction\",1:\"gender\",2:\"lsat\",3:\"pass_bar\",4:'ugpa',5:\"ugpa_above_threshold\",6:\"asian\",7:\"black\",8:\"hisp\",9:\"white\"})\n",
        "df_asian_bl_av= generate_samples(asian_bl_av_to_be_incresed,df_asian_bl_av,'law').rename(columns={0:\"dnn_bar_pass_prediction\",1:\"gender\",2:\"lsat\",3:\"pass_bar\",4:'ugpa',5:\"ugpa_above_threshold\",6:\"asian\",7:\"black\",8:\"hisp\",9:\"white\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukAJuUVOls5M",
        "outputId": "6bc2c3e3-b3b3-4161-c4db-0e6d9e3986f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The oversampled data has shape -- (112944, 10)\n"
          ]
        }
      ],
      "source": [
        "df_white_bl_av= (data[(data['ugpa_above_threshold'] == 0) & (data['white'] == 1)])\n",
        "# combining all the oversampled aubgroups\n",
        "data_oversampled_main = df_white_ab_av.append([df_black_ab_av,df_black_bl_av,df_white_bl_av,df_hisp_ab_av,df_hisp_bl_av,df_asian_ab_av,df_asian_bl_av])\n",
        "data_oversampled = data_oversampled_main\n",
        "print('The oversampled data has shape --',data_oversampled.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9YP3AJRsMDx"
      },
      "source": [
        "## Removal of biased data points using situation testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KoJkD51jyv8",
        "outputId": "bcb835a7-76a5-4bf3-946f-51fc48c2663a"
      },
      "outputs": [],
      "source": [
        "data_oversampled['new_index'] = range(0,112944) # fair SMOTE implementation return repetitive indexes according to the subgroup\n",
        "_data_oversampled = data_oversampled.set_index('new_index')\n",
        "\n",
        "X_train, y_train = _data_oversampled.loc[:, _data_oversampled.columns != 'ugpa_above_threshold'], _data_oversampled['ugpa_above_threshold']\n",
        "\n",
        "clf = LogisticRegression(C=1.0, penalty='l2', solver='liblinear', max_iter=100)\n",
        "clf.fit(X_train,y_train)\n",
        "removal_list = []\n",
        "\n",
        "for index,row in X_train.iterrows():\n",
        "    row_ = [row.values[0:len(row.values)]]    \n",
        "    y_normal = clf.predict(row_)\n",
        "\n",
        "    #switching for asian\n",
        "\n",
        "    if row_[0][5] == 1:\n",
        "      change_to_1 = random.choice([6,7,8])\n",
        "      row_[0][5] = 0\n",
        "      row_[0][change_to_1] = 1   \n",
        "      y_reverse = clf.predict(row_)\n",
        "      if y_normal[0] != y_reverse[0]:\n",
        "          removal_list.append(index)\n",
        "\n",
        "    #switching for black\n",
        "\n",
        "    if row_[0][6] == 1:\n",
        "      change_to_1 = random.choice([5,7,8])\n",
        "      row_[0][6] = 0\n",
        "      row_[0][change_to_1] = 1   \n",
        "      y_reverse = clf.predict(row_)\n",
        "      if y_normal[0] != y_reverse[0]:\n",
        "          removal_list.append(index)\n",
        "\n",
        "    #switching for hisp\n",
        "\n",
        "    if row_[0][7] == 1:\n",
        "      change_to_1 = random.choice([5,6,8])\n",
        "      row_[0][7] = 0\n",
        "      row_[0][change_to_1] = 1   \n",
        "      y_reverse = clf.predict(row_)\n",
        "      if y_normal[0] != y_reverse[0]:\n",
        "          removal_list.append(index)\n",
        "\n",
        "    #switching for white\n",
        "\n",
        "    if row_[0][8] == 1:\n",
        "      change_to_1 = random.choice([5,6,7])\n",
        "      row_[0][8] = 0\n",
        "      row_[0][change_to_1] = 1   \n",
        "      y_reverse = clf.predict(row_)\n",
        "      if y_normal[0] != y_reverse[0]:\n",
        "          removal_list.append(index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVSiU_dn6bai",
        "outputId": "967a54e1-b259-43cf-87fa-e9813c2961c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A total of 2693 instances are biased and will be removed\n"
          ]
        }
      ],
      "source": [
        "removal_list = list(set(removal_list))\n",
        "\n",
        "print(f'A total of {len(removal_list)} instances are biased and will be removed')\n",
        "_df = data_oversampled\n",
        "_remov = removal_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbKQvvuo81th",
        "outputId": "d896a682-9bc1-4bed-d3d4-7496818a3af3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of final dataset is  110251\n"
          ]
        }
      ],
      "source": [
        "# removing biased datapoints \n",
        "final = _data_oversampled.drop(_data_oversampled.index[list(set(removal_list))])\n",
        "print('Size of final dataset is ',len(final))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZfQWXW1-l9m"
      },
      "outputs": [],
      "source": [
        "# uncomment to save dataset\n",
        "\n",
        "# final.to_csv('fairSMOTE.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGgwqrDSHshv"
      },
      "source": [
        "# Evaluation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccz88jSer8Y7"
      },
      "source": [
        "## Linear Regression on balanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIQoAW_xZzg4",
        "outputId": "af7c01f8-e638-47c8-e795-cee164b7de39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear regression with protected attribute\n",
            "Intercept:  2827352022014.907\n",
            "Root Mean Square Error:  0.14294128143210394\n",
            "R^2 Value:  0.4247416874618253\n"
          ]
        }
      ],
      "source": [
        "# training linear regression model to evaluate \n",
        "data_oversampled_onlyugpa = final.drop('ugpa_above_threshold',axis = 1)\n",
        "df = data_oversampled_onlyugpa\n",
        "X = df.iloc[:,df.columns != 'ugpa']\n",
        "\n",
        "Y = df['ugpa']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state= 0)\n",
        "\n",
        "model = linear_model.LinearRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "y_pred_w_prot_attr = model.predict(X_test)\n",
        "\n",
        "rmsd = np.sqrt(mean_squared_error(Y_test, y_pred_w_prot_attr))      \n",
        "r2_value = r2_score(Y_test, y_pred_w_prot_attr)                     \n",
        "                   \n",
        "print('Linear regression with protected attribute')\n",
        "\n",
        "print(\"Intercept: \", model.intercept_)\n",
        "print(\"Root Mean Square Error: \", rmsd)\n",
        "print(\"R^2 Value: \", r2_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_g8w2AG3JSV",
        "outputId": "5913787b-2fc0-4d13-b89e-ad508f167384"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear regression without protected attribute\n",
            "Intercept:  -2.3331522728205285\n",
            "Root Mean Square Error:  0.14302452899973964\n",
            "R^2 Value:  0.4240714430118606\n"
          ]
        }
      ],
      "source": [
        "# Linear regression without protected attribute \n",
        "_df = final.drop(['asian','black','hisp','white','ugpa_above_threshold'], axis = 1)\n",
        "X = _df.iloc[:,_df.columns != 'ugpa']\n",
        "Y = _df['ugpa']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state= 0)\n",
        "\n",
        "model = linear_model.LinearRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "y_pred_wo_prot_attr = model.predict(X_test)\n",
        "\n",
        "rmsd = np.sqrt(mean_squared_error(Y_test, y_pred_wo_prot_attr))      \n",
        "r2_value = r2_score(Y_test, y_pred_wo_prot_attr)  \n",
        "                   \n",
        "print('Linear regression without protected attribute')\n",
        "print(\"Intercept: \", model.intercept_)\n",
        "print(\"Root Mean Square Error: \", rmsd)\n",
        "print(\"R^2 Value: \", r2_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1EYiE883kyY",
        "outputId": "6e8f7b3b-f84d-4bdc-d456-85b6d9219c54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Statistical Parity is  0.003038410956419213\n"
          ]
        }
      ],
      "source": [
        "# Statistical Parity\n",
        "\n",
        "averageCounter = 0\n",
        "for entry in y_pred_w_prot_attr:\n",
        "  if entry > threshold : averageCounter+=1\n",
        "prob_w_prot_attr = averageCounter/len(y_pred_w_prot_attr)\n",
        "\n",
        "\n",
        "averageCounter = 0\n",
        "for entry in y_pred_wo_prot_attr:\n",
        "  if entry > threshold : averageCounter+=1\n",
        "prob_wo_prot_attr = averageCounter/len(y_pred_wo_prot_attr)\n",
        "\n",
        "print('Statistical Parity is ', abs(prob_w_prot_attr-prob_wo_prot_attr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Hux2nxfrNvP",
        "outputId": "ded9b239-4528-4448-d1df-5df27c4a7571"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fairlearn/metrics/_metric_frame.py:67: FutureWarning: You have provided 'metrics', 'y_true', 'y_pred' as positional arguments. Please pass them as keyword arguments. From version 0.10.0 passing them as positional arguments will result in an error.\n",
            "  FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.11429500138410201\n"
          ]
        }
      ],
      "source": [
        "# Bounded Group Loss\n",
        "\n",
        "def apply_complex_function(x): \n",
        "  if x['black'] == 1:\n",
        "    return 0\n",
        "  if x['asian'] == 1:\n",
        "    return 2\n",
        "  if x['white'] == 1:\n",
        "    return 1\n",
        "  if x['hisp'] == 1:\n",
        "    return 3\n",
        "\n",
        "df = final \n",
        "df['race'] = df.apply(apply_complex_function, axis=1) \n",
        "  \n",
        "  \n",
        "df = df.drop(['asian','black','hisp','white'], axis = 1)\n",
        "X = df.iloc[:,df.columns != 'ugpa']\n",
        "Y = df['ugpa']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state= 0)\n",
        "\n",
        "\n",
        "bgl = BoundedGroupLoss(ZeroOneLoss(), upper_bound=0.1)\n",
        "sensitive_features = np.array(list(X_test['race'].values))\n",
        "mae_frame = MetricFrame(mean_absolute_error,\n",
        "                        Y_test, y_pred_w_prot_attr,\n",
        "                        sensitive_features=pd.Series(sensitive_features, name=\"SF 0\"))\n",
        "print(mae_frame.overall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFH59C2c0nwb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "BarDataset_thirdQuartile.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
